{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/culbec/facultate/AI/lab08-textgeneration-culbec/.env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from markov import Markov\n",
    "import markovify\n",
    "\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "import sacrebleu\n",
    "\n",
    "import nltk\n",
    "#nltk.download(\"vader_lexicon\")\n",
    "#nltk.download(\"punkt\")\n",
    "#nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "        Reads a text from a given file.\n",
    "        \n",
    "        :param file_path: A readable file.\n",
    "        \n",
    "        :rtype: str\n",
    "        :return: The read text from the file.\n",
    "    \"\"\"\n",
    "    \n",
    "    text = []\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            text.append(line.strip())\n",
    "            \n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def generate(m : Markov | markovify.Text, _input: str, first_word: str, no_words: int = 20) -> str:\n",
    "    if isinstance(m, Markov):\n",
    "        return m.generate(_input, first_word, no_words)\n",
    "    if isinstance(m, markovify.Text):\n",
    "        return m.make_sentence()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_from_dataset(m: Markov | markovify.Text, _input: str, first_word: str = None, no_words: int = 20):\n",
    "    if isinstance(m, Markov):\n",
    "        return m.generate(_input, first_word, no_words)\n",
    "    if isinstance(m, markovify.Text):\n",
    "        return m.make_short_sentence(min_chars=500, max_chars=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "proverbe_path = \"./data/proverbe.txt\"\n",
    "poezii_path = \"./data/corpus_complet.txt\"\n",
    "gutenberg_poetry = load_dataset(\"biglam/gutenberg-poetry-corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text (no model): \n",
      "Oarbe  de glod şi dintro\n",
      " parte  co sã ştii\n",
      " ce trăi pe străzi şi\n",
      " pe catafalcul falnic domnind\n",
      "Generated text (markovify): \n",
      "Bunul gospodar isi aduce anul ce imi e cald.\n"
     ]
    }
   ],
   "source": [
    "# Poezie fara model\n",
    "my_m = Markov(no_states=3, is_file=True)\n",
    "my_text = generate(my_m, _input=poezii_path, first_word=None, no_words=20)\n",
    "print(f\"Generated text (no model): \\n{my_text}\")\n",
    "\n",
    "# Proverb cu model markovify\n",
    "text = read_text(proverbe_path)\n",
    "markovify_m = markovify.Text(text, state_size=1)\n",
    "markovify_text = generate(markovify_m, _input=proverbe_path, first_word=None, no_words=20)\n",
    "print(f\"Generated text (markovify): \\n{markovify_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sentiment(sia: SentimentIntensityAnalyzer, text: str):\n",
    "    return sia.polarity_scores(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_with_synonyms(text: str) -> str:\n",
    "    import random\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    for i in range(len(tokens)):\n",
    "        if random.random() > 0.2:\n",
    "            synonyms = wordnet.synsets(tokens[i])\n",
    "            if synonyms:\n",
    "                syn = random.choice(synonyms).lemmas()[0].name()\n",
    "                tokens[i] = syn\n",
    "                \n",
    "    new_text = ''\n",
    "    for i in range(len(tokens)):\n",
    "        new_text += ' ' + tokens[i]\n",
    "        \n",
    "        if (i + 1) % 5 == 0:\n",
    "            new_text += \"\\n\"\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English poem (no model): \n",
      "Margaret caroline davenport was assured however\n",
      " it soon as i should\n",
      " tell you ask where nawadaha\n",
      " found these legends he might\n",
      " prosper that he had used\n",
      " to rock me tell us\n",
      " of the green and the\n",
      " ojibway tribe at la pointe\n",
      " wisconsin and toiled and the\n",
      " green and compiled much of\n",
      " the green and being how\n",
      " he completed it soon as\n",
      " i close my eyelids should\n",
      " you ask where nawadaha found\n",
      " these legends he lived and\n",
      " the ojibways from the green\n",
      " prairie who love the poem\n",
      " was assured however it soon\n",
      " as follow in the great\n",
      " rivers with the fenlands\n",
      "\n",
      "Sentiment: {'neg': 0.0, 'neu': 0.876, 'pos': 0.124, 'compound': 0.9231}\n",
      "\n",
      "English poem with synonyms: \n",
      " Margaret Caroline davenport was assured\n",
      " however information_technology soon as I\n",
      " should tell you necessitate where\n",
      " nawadaha discover these legend he\n",
      " might prosper that helium have\n",
      " use to Rock Maine tell\n",
      " U of the green and\n",
      " the Ojibwa tribe astatine la\n",
      " pointe Wisconsin and toiled and\n",
      " the green and compiled much\n",
      " of the green and be\n",
      " how helium completed information_technology soon\n",
      " deoxyadenosine_monophosphate one close my eyelids\n",
      " should you ask where nawadaha\n",
      " find these legends helium be\n",
      " and the ojibways from the\n",
      " green prairie World_Health_Organization love the\n",
      " poem Washington assure however it\n",
      " soon arsenic succeed Indiana the\n",
      " great river with the marsh\n",
      "\n",
      "\n",
      "BLEU score: 0.0\n"
     ]
    }
   ],
   "source": [
    "# English poem\n",
    "markovify_m = markovify.Text(' '.join(gutenberg_poetry['train']['line'][:100]), state_size=2)\n",
    "my_m = Markov(no_states=3, is_file=False)\n",
    "\n",
    "my_poem = generate_from_dataset(my_m, _input=' '.join(gutenberg_poetry['train']['line'][:100]), no_words=100)\n",
    "print(f\"English poem (no model): \\n{my_poem}\")\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "print(f\"\\nSentiment: {compute_sentiment(sia, ' '.join(my_poem.split('\\n')))}\")\n",
    "\n",
    "new_poem = replace_with_synonyms(my_poem)\n",
    "print(f\"\\nEnglish poem with synonyms: \\n{new_poem}\")\n",
    "\n",
    "# reference = [[word.lower().strip()] for word in ' '.join(my_poem.split('\\n')).split()]\n",
    "# actual = [word.lower().strip() for word in ' '.join(new_poem.split('\\n')).split()]\n",
    "\n",
    "reference = [sentence.strip() for sentence in my_poem.split('\\n')]\n",
    "actual = [sentence.strip() for sentence in new_poem.split('\\n')]\n",
    "\n",
    "bleu = sacrebleu.corpus_bleu(actual, reference)\n",
    "\n",
    "print(f\"\\nBLEU score: {bleu.score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
